
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>3. Supervised learning and image classification &#8212; Open Nighttime Lights</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4. Intro to Sentinel-2" href="mod6_3_intro_to_sentinel2.html" />
    <link rel="prev" title="2. Framing the analysis" href="mod6_1_framing_the_analysis.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/wb_logo.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Open Nighttime Lights</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../welcome.html">
   Welcome
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 1 Introduction to remote sensing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mod1_1_introduction_to_remote_sensing.html">
   1. Introduction to remote sensing (20 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod1_2_introduction_to_nighttime_light_data.html">
   2. Introduction to nighttime light data (20 min)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 2 Introduction to open data and tools
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mod2_1_data_overview.html">
   1. Data overview (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod2_2_getting_started_with_Python.html">
   2. Getting started with Python (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod2_3_introduction_to_Jupyter_notebooks.html">
   3. Introduction to Jupyter notebooks (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod2_4_introduction_to_GEE.html">
   4. Introduction to Google Earth Engine (GEE) (5 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod2_5_GEE_PythonAPI_and_geemap.html">
   5. GEE Python API and geemap (5 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod2_6_practical_exercise-image_visualization.html">
   6. Practical exercise: image visualization (10 min)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 3 Basic operations on raster files
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_1_DMSP-OLS_annual_composites.html">
   1. DMSP-OLS annual composites in Google Earth Engine (5 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_2_image_clipping_with_VIIRS.html">
   2. Image clipping with VIIRS-DNB (5 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_3_conditional_operations.html">
   3. Conditional operations (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_4_cell_statistics_band_math.html">
   4. Cell statistics and basic band math (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_5_expressions-PartA.html">
   5. Expressions (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_5_expressions-PartB.html">
   6. Expressions (continued)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_6_making_VIIRS_annual_composites.html">
   7. Making simple VIIRS-DNB annual composites (5 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod3_7_import_export_data.html">
   8. Importing and exporting data (5 min)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 4 Charting
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mod4_1_time_series_charts.html">
   1. Time Series Charts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod4_2_histograms.html">
   2. Histograms
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 5 Data analysis and intercalibration
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mod5_1_DMSP-OLS_intercalibration.html">
   1. DMSP-OLS intercalibration (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod5_2_rate_of_change.html">
   2. Calculate rate of change (5 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod5_3_vector_and_raster_data.html">
   3. Working with vector and raster data (10 min)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod5_4_comparing_cities.html">
   4. Comparing cities (5 min)
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 6 Exercise in data fusion for image classification
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_0_overview.html">
   1. Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_1_framing_the_analysis.html">
   2. Framing the analysis
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3. Supervised learning and image classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_3_intro_to_sentinel2.html">
   4. Intro to Sentinel-2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_4_intro_to_GHSL.html">
   5. Intro to Global Human Settlement Layer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_5_data_fusion.html">
   6. Data fusion: Sentinel-2, VIIRS-DNB, GHSL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_6_RF_classifier.html">
   7. Random Forest Classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mod6_7_final_analysis.html">
   8. Statistical inference
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  World Bank - Light Every Night AWS data archive
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../wb-light-every-night-readme.html">
   World Bank - Light Every Night
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Applications of nighttime lights
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../estimating-electricity-with-viirs.html">
   High Resolution Electricity Access (HREA) Indicators
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/tutorials/mod6_2_supervised_learning_img_classification.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#supervised-learning">
   3.1. Supervised learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-with-image-data">
   3.2. Classification with image data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-most-important-kind-of-learning-yours">
   3.3. The most important kind of learning: yours
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   3.4. References:
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="supervised-learning-and-image-classification">
<h1><span class="section-number">3. </span>Supervised learning and image classification<a class="headerlink" href="#supervised-learning-and-image-classification" title="Permalink to this headline">¶</a></h1>
<p>We should introduce two important concepts that we have not yet covered in the tutorials. We only scratch the surface, but encourage you to learn more about these powerful techniques.</p>
<div class="alert alert-info">
As Cassie Kozyrkov, Chief Decision Scientist at Google, states <a href="https://kozyrkov.medium.com/machine-learning-is-the-emperor-wearing-clothes-928fe406fe09">(in a very accessible description of machine learning)</a>, "machine learning uses patterns in data to label things."</div>
<p>A machine learning algorith is a thing-labeler. The complexity and nuance of “things” to label and the performance of the labeler can get really advanced, but as a basic concept, it’s really that simple.</p>
<div class="section" id="supervised-learning">
<h2><span class="section-number">3.1. </span>Supervised learning<a class="headerlink" href="#supervised-learning" title="Permalink to this headline">¶</a></h2>
<div class="alert alert-info">
**Supervised learning** is an approach that uses already-labeled data to learn associations between these labels and a given set of attributes or features, the likelihood of a particular label, such that the algorithm can predict labels on unseen data that are not labeled but have the same features.</div>
<p>If the labels were continuous (e.g. the amount of rain in a given day) the approach would be regression. If the labels were categorical, including binary (e.g. whether it rains in a given day or not), the approach would be classification.</p>
<p>For our exercise, we are predicting if a pixel is “built-up” or not (binary classification), using the Global Human Settlement Layer (GHSL) data to define what “built-up” means. GHSL categorizes grid cells as being either “high density” (cities), “low density” (cities and towns), or “rural,” so we will simplify this as being built up (either high or low density) versus not (everything else).</p>
<p>We are using VIIRS-DNB and Sentinel-2 image attributes as our input features. Since we have GHSL data from 2015, we will use data from that year to learn the association of VIIRS-DNB and Sentinel-2 measurements and built-up land. Then we can apply this learned association to data that does not have any GHSL label (i.e. any year after 2015) and make a prediction about whether it is built up based only on VIIRS-DNB and Sentinel-2 inputs.</p>
</div>
<div class="section" id="classification-with-image-data">
<h2><span class="section-number">3.2. </span>Classification with image data<a class="headerlink" href="#classification-with-image-data" title="Permalink to this headline">¶</a></h2>
<p>Hopefully the concept of “thing-labeling” for land classification task is clear, but it might be confusing how exactly our model will learn the association of input features, like VIIRS-DNB and Sentinal-2 with a label such as “built-up.”</p>
<p>Image classification is a useful and popular application of machine learning and computer vision. It most commonly refers to the task of classifying an entire image (or the dominant object in an image, such as a cat) based on the image’s pixels as input.</p>
<p>It is also possible to classify individual pixels as well, which is the task appropriate to our exercise.</p>
<p>Recall from <span class="xref std std-doc">tutorials/mod2_1_data_overview</span> that data can be stored in raster files, which are like grids of cells (i.e. pixels). All three data sources we are working with, VIIRS-DNB, Sentinel-2, and GHSL, will be formatted in raster files. So consider each grid cell/pixel in the raster as an observation that contains certain features: the values from corresponding VIIRS-DNB nighttime or Sentinel-2 MSI images. And for our 2015 training data it will also contain a label: the GHSL classification as “built-up” (1) or not (0). For the data that is not in our training set, our inference data, we will only have VIIRS-DNB and Sentinel-2 values and will have to predict the label.</p>
<p>Our classifier’s task is to learn what levels of input features are assocated with a given label based on analysis of all the labeled pixels in our training dataset image (from 2015). When we pass new images from 2016-2019, the classifier will predict the likelihood of a pixel being “built up” based on what it sees in terms of VIIRS-DNB and Sentinel-2 data and what it learned from training about the likelihood of those values corresponding to built-up land.</p>
<p>While there are advanced methods of deep learning well-suited to image analysis, such as Convolutional Neural Nets (CNNs), Random Forest (RF) is a simple but often effective classifier to use for this beginner’s task.</p>
<p>You may ask whether other information, such as the values of neighboring pixels, is important…yes! Most advanced image classifiers will take advantage of such contextual information as well. Additionally, feature engineering, including mathmatical transformations, and additional data can often improve classifiers a lot. Since we are investigating changes in time, we should also be concerned with the influence of the past on the future (hint: it does) and how that impacts model training and inference…but for our exercise, we’re sticking with the basics.</p>
</div>
<div class="section" id="the-most-important-kind-of-learning-yours">
<h2><span class="section-number">3.3. </span>The most important kind of learning: yours<a class="headerlink" href="#the-most-important-kind-of-learning-yours" title="Permalink to this headline">¶</a></h2>
<p>This is a very brief summary of some fairly deep topics but many resources are available for learning more. Two excellent texts cover the fundamentals for the ideas described here: “Pattern Recognition and Machine Learning” <a class="bibtex reference internal" href="#bishop2006pattern" id="id1">[Bis06]</a>, and “The Elements of Statistical Learning: Data Mining, and Prediction” <a class="bibtex reference internal" href="#hastie2009elements" id="id2">[HTF09]</a>. And of course the internet is awash with free and accessible online courses at many levels.</p>
<div class="alert alert-success">
Python itself provides a useful entry point for these methods via the <a href="https://scikit-learn.org/stable/user_guide.html">documention in the scikit-learn package</a>. And the added benefit is that the packages described contain the very code needed to implement these methods and many examples.
</div>
<p>The good news is that as long as you stay curious about what you are doing and why, the tools for doing this classification are easy to use and require minimal programming experience, as with the previous tutorial exercises.</p>
<p>Do not let a lack of knowledge prevent you from digging into the data and learning by doing, but rather consider the resources available for understanding applicable theory when something interesting happens with your data and you want to know why. Once you do, you will see what is possible and hopefully be motivated to learn more.</p>
</div>
<div class="section" id="references">
<h2><span class="section-number">3.4. </span>References:<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-tutorials/mod6_2_supervised_learning_img_classification-0"><dl class="citation">
<dt class="bibtex label" id="bishop2006pattern"><span class="brackets"><a class="fn-backref" href="#id1">Bis06</a></span></dt>
<dd><p>Christopher M Bishop. <em>Pattern recognition and machine learning</em>. springer, 2006.</p>
</dd>
<dt class="bibtex label" id="hastie2009elements"><span class="brackets"><a class="fn-backref" href="#id2">HTF09</a></span></dt>
<dd><p>Trevor Hastie, Robert Tibshirani, and Jerome Friedman. <em>The elements of statistical learning: data mining, inference, and prediction</em>. Springer Science &amp; Business Media, 2009.</p>
</dd>
</dl>
</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="mod6_1_framing_the_analysis.html" title="previous page"><span class="section-number">2. </span>Framing the analysis</a>
    <a class='right-next' id="next-link" href="mod6_3_intro_to_sentinel2.html" title="next page"><span class="section-number">4. </span>Intro to Sentinel-2</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By World Bank<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>